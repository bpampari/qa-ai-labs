# ğŸš€ QA AI Labs â€“ Building Local AI Agents for Quality Engineering

This repository documents a structured, hands-on journey of building practical AI agents for Software Testing using a fully local setup.

The goal was not to use AI tools â€” but to design and build AI systems.

## ğŸ§  Project Objective

To design and implement:

- Context-aware AI agents
- Failure-aware automation repair loops
- Local LLM-based assistants
- Guarded AI file rewrite mechanisms
- Telegram-based productivity bots
- Lightweight 24x7 background agents
- All running locally without paid APIs.

## ğŸ— System Overview

Everything runs on a single Windows machine acting as a local AI server.

```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Windows PC (Server)   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                      â”‚                      â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Ollama LLM  â”‚       â”‚ Selenium Java  â”‚      â”‚ Telegram Bot  â”‚
 â”‚ qwen2.5:1.5b â”‚      â”‚ Framework      â”‚      â”‚ API           â”‚
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                      â”‚                      â”‚
        â”‚               â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
        â”‚               â”‚ Python AI Agentsâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                      â”‚
        â”‚               â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚ Context Serverâ”‚
        â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‚ Repository Structure

```
qa-ai-labs/
â”‚
â”œâ”€â”€ selenium-ai-framework/
â”‚   â”œâ”€â”€ src/test/java/pages/
â”‚   â”œâ”€â”€ src/test/java/tests/
â”‚   â”œâ”€â”€ BaseTest.java
â”‚   â””â”€â”€ pom.xml
â”‚
â”œâ”€â”€ context-server/
â”‚   â””â”€â”€ server.py
â”‚
â”œâ”€â”€ ai-agents/
â”‚   â”œâ”€â”€ mcp-agent/
â”‚   â”œâ”€â”€ self-heal-agent/
â”‚   â”‚   â””â”€â”€ self_heal.py
â”‚   â””â”€â”€ telegram-agent/
â”‚       â””â”€â”€ daily_bot.py
â”‚
â””â”€â”€ README.md
```


## ğŸ§ª Phase 1 â€“ Local LLM Infrastructure

**We installed:**

- Ollama
- Lightweight model (qwen2.5:1.5b)
- Python requests-based API calls

**Learning:**

- Local models require strict token discipline
- Larger prompts cause timeouts
- Memory constraints matter

## ğŸ¤– Phase 2 â€“ Context-Aware MCP-Style Agent

**Problem**

LLMs hallucinate when they lack project awareness.

**Solution**

- Built a local context server that:
- Reads project files
- Exposes them via HTTP endpoint
- Sends relevant files to LLM

**Flow:**

```
qa-ai-labs/
â”‚
â”œâ”€â”€ selenium-ai-framework/
â”‚   â”œâ”€â”€ src/test/java/pages/
â”‚   â”œâ”€â”€ src/test/java/tests/
â”‚   â”œâ”€â”€ BaseTest.java
â”‚   â””â”€â”€ pom.xml
â”‚
â”œâ”€â”€ context-server/
â”‚   â””â”€â”€ server.py
â”‚
â”œâ”€â”€ ai-agents/
â”‚   â”œâ”€â”€ mcp-agent/
â”‚   â”œâ”€â”€ self-heal-agent/
â”‚   â”‚   â””â”€â”€ self_heal.py
â”‚   â””â”€â”€ telegram-agent/
â”‚       â””â”€â”€ daily_bot.py
â”‚
â””â”€â”€ README.md
```

**Learning**

- Sending entire project increases token overload
- Must limit context to relevant files only


## ğŸ”§ Phase 3 â€“ Self-Healing Selenium Prototype

**Objective**

Automatically detect failing Selenium tests and attempt AI-driven repair

```
Run mvn test
      â†“
Detect failure
      â†“
Capture stacktrace
      â†“
Capture page-source.html
      â†“
Send failure + DOM + file to LLM
      â†“
AI generates updated Java class
      â†“
Sanitize output
      â†“
Overwrite file (with validation)
      â†“
Re-run tests

```

**Engineering Challenges Faced**

1ï¸âƒ£ Token Overload

Full HTML + logs caused LLM timeouts.

Fix:

Trim logs

Trim HTML

Send only relevant file

2ï¸âƒ£ Markdown Artifacts

AI returned:

java
package pages;


Fix:

Strip ```java blocks

Remove leading â€œjavaâ€

Add structural validation


3ï¸âƒ£ Missing Imports

AI modified file but removed required imports.

Fix:

Prompt guardrails

Structural keyword validation

4ï¸âƒ£ Risk of File Corruption

AI could overwrite with invalid content.

Guardrail Added:

```
if not fix_code.strip().startswith("package pages"):
    exit()

```

**Key Insights**

AI is not deterministic.

You must build:

- Validation layer

- Sanitation layer

- Guardrail layer

- Retry strategy

Self-healing is possible â€” but requires strong control.


## ğŸ“¬ Phase 4 â€“ Telegram QA Learning Agent

**Objective**

Send daily QA tips using local LLM.

**Flow**

Scheduler Trigger
      â†“
Generate Structured Prompt
      â†“
Call Ollama
      â†“
Send Message via Telegram API

**Features**

Theme rotation

Low token usage

Runs via Task Scheduler

Fully local AI generation


# ğŸ‘¨â€ğŸ’» Author

Balakrishna Pampari
Quality Engineer
AI in Testing Practitioner
Building toward AI Automation Architecture
